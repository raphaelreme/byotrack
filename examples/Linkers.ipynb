{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e8f341e",
   "metadata": {},
   "source": [
    "# Linkers\n",
    "\n",
    "Review of all the linkers implemented in ByoTrack. For more details, have a look at the documentation or implementation of each linker.\n",
    "___________________________________________________\n",
    "\n",
    "1. **NearestNeighborLinker** (Frame by frame linker using euclidean distance association)\n",
    "2. **KalmanLinker** (Frame by frame linker that models motion with Kalman filters and use maximum likelihood association\n",
    "3. **KOFTLinker** (Frame by frame linker that models motion using Optical Flow enhanced Kalman filters and maximum likelihood association)\n",
    "4. **IcyEMHTLinker** (Wrapper around Icy EMHT algorithm that uses Kalman filters and multiple hypothesis association)\n",
    "2. **TrackMateLinker** (Wrapper around u-track/TrackMate from Fiji. It uses Kalman filters and euclidean distance based association)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52925781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "import byotrack\n",
    "import byotrack.example_data\n",
    "import byotrack.visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1ea9b3",
   "metadata": {},
   "source": [
    "## Load a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a725f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open an example video\n",
    "video = byotrack.example_data.hydra_neurons()[130:]  # Let's start at frame 130 where the animal is contracting\n",
    "\n",
    "# Or provide a path to one of your video\n",
    "#video = byotrack.Video(\"path/to/video.ext\")\n",
    "\n",
    "# Or load manually a video as a numpy array\n",
    "# video = np.random.randn(50, 500, 500, 3)  # T, H, W, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae4d263",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST = True  # Set to False to analyze a whole video\n",
    "\n",
    "if TEST:\n",
    "    video = video[:50]  # Temporal slicing to analyze only the first 50 frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e362ba7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A transform can be added to normalize and aggregate channels\n",
    "\n",
    "transform_config = byotrack.VideoTransformConfig(aggregate=True, normalize=True, q_min=0.01, q_max=0.999, smooth_clip=1.0)\n",
    "video.set_transform(transform_config)\n",
    "\n",
    "# Show the min max value used to clip and normalize\n",
    "print(video._normalizer.mini, video._normalizer.maxi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f187648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first frame\n",
    "\n",
    "plt.figure(figsize=(24, 16), dpi=100)\n",
    "plt.imshow(video[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a47b610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the video with opencv\n",
    "# Use w/x to move forward in time (or space to run/pause the video)\n",
    "# Use v to switch on/off the display of the video\n",
    "\n",
    "byotrack.visualize.InteractiveVisualizer(video).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd6f82e",
   "metadata": {},
   "source": [
    "## Detections\n",
    "\n",
    "The linker links detections through time. We use the WaveletDetector from byotrack as an example to produce the detections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4193249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the detector object with its hyper parameters\n",
    "from byotrack.implementation.detector.wavelet import WaveletDetector\n",
    "\n",
    "detector = WaveletDetector(scale=1, k=3.0, min_area=5.0, batch_size=20, device=torch.device(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdee8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the detection process on the current video\n",
    "\n",
    "detections_sequence = detector.run(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8388216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the detections with opencv\n",
    "# Use w/x to move forward in time (or space to run/pause the video)\n",
    "# Use v to switch on/off the display of the video\n",
    "# Use d to switch detection display mode (None, mask, segmentation)\n",
    "\n",
    "byotrack.visualize.InteractiveVisualizer(video, detections_sequence).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568cfef3",
   "metadata": {},
   "source": [
    "## NearestNeighborLinker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899c9c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from byotrack.implementation.linker.frame_by_frame.nearest_neighbor import NearestNeighborLinker, NearestNeighborParameters, AssociationMethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dc94dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See documentation about the Linker\n",
    "\n",
    "NearestNeighborLinker?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda29ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See documentation about the Linker parameters\n",
    "\n",
    "NearestNeighborParameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9635c18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the linker\n",
    "# We set only the main parameters\n",
    "# You can look at the documentation to see the other ones\n",
    "\n",
    "specs = NearestNeighborParameters(\n",
    "    association_threshold=10.0,  # Most important one: Don't link if the euclidean distance is greater than 10 pixels\n",
    "    n_valid=3,  # Validate a track after three consecutive detections\n",
    "    n_gap=3,  # At most 3 consecutive missed detections\n",
    "    association_method=\"opt_smooth\"  # See AssociationMethod?, you can use greedy which is faster but usually less performant\n",
    ")\n",
    "\n",
    "linker = NearestNeighborLinker(specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404c701f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the linker\n",
    "\n",
    "tracks = linker.run(video, detections_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f03950a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the tracks with opencv\n",
    "# Use w/x to move forward in time (or space to run/pause the video)\n",
    "# Use v (resp. t) to switch on/off the display of video (resp. tracks)\n",
    "# Use d to switch detection display mode (None, mask, segmentation)\n",
    "\n",
    "byotrack.visualize.InteractiveVisualizer(video, detections_sequence, tracks).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6d5ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project tracks onto a single image and color by time\n",
    "\n",
    "# Create a list of colors for each time frame\n",
    "# From cyan (start of the video) to red (end of the video)\n",
    "\n",
    "hsv = mpl.colormaps[\"hsv\"]\n",
    "colors = [tuple(int(c * 255) for c in hsv(0.5 + 0.5 * k / (len(detections_sequence) - 1))[:3]) for k in range(len(detections_sequence))]\n",
    "\n",
    "visu = byotrack.visualize.temporal_projection(\n",
    "    byotrack.Track.tensorize(tracks),\n",
    "    colors=colors,\n",
    "    background=None,\n",
    "    color_by_time=True\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(24, 16))\n",
    "plt.imshow(visu)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0016ed",
   "metadata": {},
   "source": [
    "## KalmanLinker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4936fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from byotrack.implementation.linker.frame_by_frame.kalman_linker import KalmanLinker, KalmanLinkerParameters, Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4468594a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See documentation about the Linker\n",
    "\n",
    "KalmanLinker?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5415a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See documentation about the Linker parameters\n",
    "\n",
    "KalmanLinkerParameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3bc75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the linker\n",
    "# We set only the main parameters.\n",
    "# You can look at the documentation to see the other ones.\n",
    "\n",
    "specs = KalmanLinkerParameters(\n",
    "    association_threshold=1e-3,  # Most important parameter: don't link if the association likelihood is smaller than 1e-4.\n",
    "    detection_std=3.0,  # Detections location are precise up to 3.0 pixels\n",
    "    process_std=3.0,  # Kalman filter predictions are precise up to 3.0 pixels\n",
    "    kalman_order=1,  # Order of the kalman filter\n",
    "    cost=\"likelihood\",  # See Cost? to see which other cost are available, by default it uses Euclidean distance (And association threshod should be express in pixels)\n",
    ")\n",
    "\n",
    "linker = KalmanLinker(specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7164434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the linker\n",
    "\n",
    "tracks = linker.run(video, detections_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3eade0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the tracks with opencv\n",
    "# Use w/x to move forward in time (or space to run/pause the video)\n",
    "# Use v (resp. t) to switch on/off the display of video (resp. tracks)\n",
    "# Use d to switch detection display mode (None, mask, segmentation)\n",
    "\n",
    "byotrack.visualize.InteractiveVisualizer(video, detections_sequence, tracks).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c98788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project tracks onto a single image and color by time\n",
    "\n",
    "# Create a list of colors for each time frame\n",
    "# From cyan (start of the video) to red (end of the video)\n",
    "\n",
    "hsv = mpl.colormaps[\"hsv\"]\n",
    "colors = [tuple(int(c * 255) for c in hsv(0.5 + 0.5 * k / (len(detections_sequence) - 1))[:3]) for k in range(len(detections_sequence))]\n",
    "\n",
    "visu = byotrack.visualize.temporal_projection(\n",
    "    byotrack.Track.tensorize(tracks),\n",
    "    colors=colors,\n",
    "    background=None,\n",
    "    color_by_time=True\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(24, 16))\n",
    "plt.imshow(visu)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146077ec",
   "metadata": {},
   "source": [
    "## KOFTLinker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1745c1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from byotrack.implementation.linker.frame_by_frame.koft import KOFTLinker, KOFTLinkerParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf5fd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See documentation about the Linker\n",
    "\n",
    "KOFTLinker?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfe1f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See documentation about the Linker parameters\n",
    "\n",
    "KOFTLinkerParameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d5b6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Koft requires optical flow (NOTE: that optical flow can also be efficiently be used with the two previous linker)\n",
    "\n",
    "# You could use any optical flow algorithm, but ByoTrack already supports OpenCV and Skimage implementations.\n",
    "# Let's use Farneback from OpenCV (no extra dependencies)\n",
    "\n",
    "import cv2\n",
    "from byotrack.implementation.optical_flow.opencv import OpenCVOpticalFlow\n",
    "\n",
    "optflow = OpenCVOpticalFlow(cv2.FarnebackOpticalFlow_create(winSize=20), downscale=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e2cebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before linking, let's check visually that the optical flow algorithm works\n",
    "# We sample a grid of points that are moved by the flow computed.\n",
    "# The computed flows are good if the points roughly follows the video motion\n",
    "\n",
    "# Use w/x to move forward in time (or space to run/pause the video)\n",
    "# Use g to reset the grid of points\n",
    "\n",
    "byotrack.visualize.InteractiveFlowVisualizer(video, optflow).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5381bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the linker\n",
    "# We set only the main parameters.\n",
    "# You can look at the documentation to see the other ones.\n",
    "\n",
    "specs = KOFTLinkerParameters(\n",
    "    association_threshold=2e-3,  # Most important parameter: don't link if the association likelihood is smaller than 1e-3.\n",
    "    detection_std=3.0,  # Detections location are precise up to 3.0 pixels\n",
    "    process_std=1.5,  # Kalman filter predictions are precise up to 3.0 pixels\n",
    "    flow_std=1.0,  # Optical flow predictions are precise up to 1.0 pixels/frame\n",
    "    kalman_order=1,  # Order of the kalman filter\n",
    "    n_gap=5,  # Allow to link after 5 consecutive missed detections\n",
    "    cost=\"likelihood\",  # See Cost? to see which other cost are available, by default it uses Euclidean distance (And association threshod should be express in pixels)\n",
    ")\n",
    "\n",
    "linker = KOFTLinker(specs, optflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25514f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the linker\n",
    "\n",
    "tracks = linker.run(video, detections_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f27dcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the tracks with opencv\n",
    "# Use w/x to move forward in time (or space to run/pause the video)\n",
    "# Use v (resp. t) to switch on/off the display of video (resp. tracks)\n",
    "# Use d to switch detection display mode (None, mask, segmentation)\n",
    "\n",
    "byotrack.visualize.InteractiveVisualizer(video, detections_sequence, tracks).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28274cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project tracks onto a single image and color by time\n",
    "\n",
    "# Create a list of colors for each time frame\n",
    "# From cyan (start of the video) to red (end of the video)\n",
    "\n",
    "hsv = mpl.colormaps[\"hsv\"]\n",
    "colors = [tuple(int(c * 255) for c in hsv(0.5 + 0.5 * k / (len(detections_sequence) - 1))[:3]) for k in range(len(detections_sequence))]\n",
    "\n",
    "visu = byotrack.visualize.temporal_projection(\n",
    "    byotrack.Track.tensorize(tracks),\n",
    "    colors=colors,\n",
    "    background=None,\n",
    "    color_by_time=True\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(24, 16))\n",
    "plt.imshow(visu)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8af001",
   "metadata": {},
   "source": [
    "## EMHT (Icy)\n",
    "\n",
    "Icy software must be installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718cce0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from byotrack.implementation.linker.icy_emht import IcyEMHTLinker, Motion, EMHTParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00b5020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See documentation about the Linker\n",
    "\n",
    "IcyEMHTLinker?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07edb81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See documentation about the Linker parameters\n",
    "\n",
    "EMHTParameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc6b522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the linker object with icy path\n",
    "# This Linker requires to install Icy software first\n",
    "\n",
    "icy_path = \"path/to/icy/icy.jar\"\n",
    "motion = Motion.MULTI  # Can also be DIRECTED or MULTI (both)\n",
    "\n",
    "if True:  # Set full specs with EMHTParameters\n",
    "    # You can choose to set manually the parameters. See EMHTParameters\n",
    "    # the more important ones are:\n",
    "    # - gate_factor: How greedy the linking is. (Default to 4.0) more or less equivalent to the association_threshold\n",
    "    #       of KalmanLinker with a Mahalanobis Cost.\n",
    "    # - motion: Motion model to consider: Can be BROWNIAN, DIRECTED or MULTI. (Default is BROWNIAN)\n",
    "    #       Brownian <=> kalman_order = 0, Directed <=> kalman_order = 1 (MULTI uses both)\n",
    "    # - tree_depth: MHT tree depth. Higher values are usually more performant, but much more expensive\n",
    "    #             If the tracking is too slow or too ram intensive, you may reduce this value. (Default 4)\n",
    "    parameters = EMHTParameters(gate_factor=4.0, motion=motion, tree_depth=2)\n",
    "    linker = IcyEMHTLinker(icy_path, parameters)\n",
    "else:  # Do not provide specs, parameters will be estimated by Icy (We do not advise this solution)\n",
    "    linker = IcyEMHTLinker(icy_path)\n",
    "    linker.motion = motion  # Set motion afterwards if no parameters are provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a26480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the linker\n",
    "\n",
    "tracks = linker.run(video, detections_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d14256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the tracks with opencv\n",
    "# Use w/x to move forward in time (or space to run/pause the video)\n",
    "# Use v (resp. t) to switch on/off the display of video (resp. tracks)\n",
    "# Use d to switch detection display mode (None, mask, segmentation)\n",
    "\n",
    "byotrack.visualize.InteractiveVisualizer(video, detections_sequence, tracks).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea0275e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project tracks onto a single image and color by time\n",
    "\n",
    "# Create a list of colors for each time frame\n",
    "# From cyan (start of the video) to red (end of the video)\n",
    "\n",
    "hsv = mpl.colormaps[\"hsv\"]\n",
    "colors = [tuple(int(c * 255) for c in hsv(0.5 + 0.5 * k / (len(detections_sequence) - 1))[:3]) for k in range(len(detections_sequence))]\n",
    "\n",
    "visu = byotrack.visualize.temporal_projection(\n",
    "    byotrack.Track.tensorize(tracks),\n",
    "    colors=colors,\n",
    "    background=None,\n",
    "    color_by_time=True\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(24, 16))\n",
    "plt.imshow(visu)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908a1d42",
   "metadata": {},
   "source": [
    "## TrackMate (Fiji)\n",
    "\n",
    "ImageJ/Fiji software must be installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8f2df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from byotrack.implementation.linker.trackmate import TrackMateLinker, TrackMateParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537019f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See documentation about the Linker\n",
    "\n",
    "TrackMateLinker?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887474bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See documentation about the Linker parameters\n",
    "\n",
    "TrackMateParameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b33ecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the linker object with fiji path\n",
    "# This Linker requires to install Fiji software first\n",
    "# We set only the main parameters.\n",
    "# You can look at the documentation to see the other ones.\n",
    "\n",
    "fiji_path = \"path/to/Fiji.app/ImageJ-os\"\n",
    "\n",
    "specs = TrackMateParameters(\n",
    "    linking_max_distance=10.0,  # Max linking euclidean distance (pixels) between consecutive spots\n",
    "    max_frame_gap=4,  # Max diff in frames to allow gap closing. Here it allows 3 consecutives missed detections\n",
    "    gap_closing_max_distance=15.0,  # Max gap closing euclidean distance (pixels).\n",
    "    kalman_search_radius=10.0  # When set, it enables Kalman filters, and replace the linking_max_distance (except for the first two spots association)\n",
    ")\n",
    "\n",
    "\n",
    "linker = TrackMateLinker(fiji_path, specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b824da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the linker\n",
    "\n",
    "tracks = linker.run(video, detections_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffceb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the tracks with opencv\n",
    "# Use w/x to move forward in time (or space to run/pause the video)\n",
    "# Use v (resp. t) to switch on/off the display of video (resp. tracks)\n",
    "# Use d to switch detection display mode (None, mask, segmentation)\n",
    "\n",
    "byotrack.visualize.InteractiveVisualizer(video, detections_sequence, tracks).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f0555b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project tracks onto a single image and color by time\n",
    "\n",
    "# Create a list of colors for each time frame\n",
    "# From cyan (start of the video) to red (end of the video)\n",
    "\n",
    "hsv = mpl.colormaps[\"hsv\"]\n",
    "colors = [tuple(int(c * 255) for c in hsv(0.5 + 0.5 * k / (len(detections_sequence) - 1))[:3]) for k in range(len(detections_sequence))]\n",
    "\n",
    "visu = byotrack.visualize.temporal_projection(\n",
    "    byotrack.Track.tensorize(tracks),\n",
    "    colors=colors,\n",
    "    background=None,\n",
    "    color_by_time=True\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(24, 16))\n",
    "plt.imshow(visu)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
