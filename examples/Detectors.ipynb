{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bca01ba2",
   "metadata": {},
   "source": [
    "# Detectors\n",
    "\n",
    "Review of all the detectors implemented in ByoTrack. For more details, have a look at the documentation or implementation of each detector.\n",
    "___________________________________________________\n",
    "\n",
    "1. **Wavelet Detector** (Wavelet decomposition + noise filtering)\n",
    "2. **StarDist** (Unet + StarConvex prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2635bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "import byotrack\n",
    "import byotrack.example_data\n",
    "import byotrack.visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9740b7b",
   "metadata": {},
   "source": [
    "## Load a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbcee8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open an example video\n",
    "video = byotrack.example_data.hydra_neurons()\n",
    "\n",
    "# Or provide a path to one of your video\n",
    "# video = byotrack.Video(\"path/to/video.ext\")\n",
    "\n",
    "# Or load manually a video as a numpy array\n",
    "# video = np.random.randn(50, 500, 500, 3)  # T, H, W, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ad295e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST = True  # Set to False to analyze a whole video\n",
    "\n",
    "if TEST:\n",
    "    video = video[:50]  # Temporal slicing to analyze only the first 50 frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04f708f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A transform can be added to normalize and aggregate channels\n",
    "\n",
    "transform_config = byotrack.VideoTransformConfig(\n",
    "    aggregate=True, normalize=True, q_min=0.01, q_max=0.999, smooth_clip=1.0\n",
    ")\n",
    "video.set_transform(transform_config)\n",
    "\n",
    "# Show the min max value used to clip and normalize\n",
    "print(video._normalizer.mini, video._normalizer.maxi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b412d113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first frame\n",
    "\n",
    "plt.figure(figsize=(24, 16), dpi=100)\n",
    "plt.imshow(video[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad343a87",
   "metadata": {},
   "source": [
    "## WaveletDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49eee7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from byotrack.implementation.detector.wavelet import WaveletDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dc7975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the Detector documentation\n",
    "\n",
    "WaveletDetector?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3241af01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the detector object with its hyper parameters. \n",
    "# The most important ones being the scale (size of the spots) and k the threshold noise\n",
    "\n",
    "detector = WaveletDetector(scale=1, k=3.0, min_area=5.0, batch_size=20, device=torch.device(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f199c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the hyperparameters manually on the video\n",
    "# Use w/x to move backward/forward in the video\n",
    "# Use c/v to update k (noise threshold)\n",
    "# Use b/n to update the scale (expected size of the spots)\n",
    "# You can also use the min_area to filter more or less spots given their area\n",
    "\n",
    "K_SPEED = 0.01\n",
    "scale = detector.scale\n",
    "\n",
    "i = 0\n",
    "\n",
    "while True:\n",
    "    frame = video[i]\n",
    "\n",
    "    # Run detection on a single frame using detect\n",
    "    detections = detector.detect(frame[None, ...])[0]\n",
    "    mask = (detections.segmentation.numpy() != 0).astype(np.uint8) * 255\n",
    "    \n",
    "    image = np.concatenate((frame, np.zeros_like(frame), mask[..., None]), axis=-1)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Frame', image)\n",
    "    cv2.setWindowTitle('Frame', f'Frame {i} / {len(video)} - scale={scale}, k={detector.k} - Num detections: {detections.length}')\n",
    "\n",
    "    # Press Q on keyboard to  exit\n",
    "    key = cv2.waitKey() & 0xFF\n",
    "\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "    if cv2.getWindowProperty(\"Frame\", cv2.WND_PROP_VISIBLE) <1:\n",
    "        break\n",
    "        \n",
    "    if key == ord(\"w\"):\n",
    "        i = (i - 1) % len(video)\n",
    "\n",
    "    if key == ord(\"x\"):\n",
    "        i = (i + 1) % len(video)\n",
    "        \n",
    "    if key == ord(\"c\"):\n",
    "        detector.k = detector.k * (1 - K_SPEED)\n",
    "\n",
    "    if key == ord(\"v\"):\n",
    "        detector.k = detector.k * (1 + K_SPEED)\n",
    "        \n",
    "    if key == ord(\"b\"):\n",
    "        scale = max(0, scale - 1)\n",
    "        detector = WaveletDetector(scale, detector.k, detector.min_area, detector.device)\n",
    "        \n",
    "    \n",
    "    if key == ord(\"n\"):\n",
    "        scale = min(4, scale + 1)\n",
    "        detector = WaveletDetector(scale, detector.k, detector.min_area, detector.device)\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bd646d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the detection process on the current video\n",
    "\n",
    "detections_sequence = detector.run(video)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da573cbb",
   "metadata": {},
   "source": [
    "## StarDist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af566665",
   "metadata": {},
   "outputs": [],
   "source": [
    "from byotrack.implementation.detector.stardist import StarDistDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a29e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the Detector documentation\n",
    "\n",
    "StarDistDetector?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37eb3006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use your active stardist model, or load a trained own or pretrained own from the official implementation:\n",
    "# Hyperparameters are usually set during the training phase (nms_treshold and prob_threshold)\n",
    "# They can be changed manually (See next cells)\n",
    "\n",
    "# From a current model:\n",
    "# detector = StarDistDetector(stardist_model, batch_size=1)\n",
    "\n",
    "# Load a pretrained model with a valid id\n",
    "# detector = StarDistDetector.from_pretrained(\"2D_versatile_fluo\", batch_size=1)\n",
    "\n",
    "# Create the detector object from a trained model. Note that the training should be done with\n",
    "# the official implementation (https://github.com/stardist/stardist).\n",
    "train_dir = \"path/to/trained/model/\"\n",
    "\n",
    "detector = StarDistDetector.from_trained(train_dir, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1b8e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the hyperparameters manually on the video\n",
    "# Use w/x to move backward/forward in the video\n",
    "# Use c/v to update prob_threshold (The most probable spots are kept)\n",
    "# Use b/n to update the nms_threshold (Delete overlapping spots)\n",
    "# You can also the min_area to filter more or less spots given their area\n",
    "\n",
    "prob_speed = 0.1\n",
    "nms_speed = 0.2\n",
    "\n",
    "i = 0\n",
    "\n",
    "while True:\n",
    "    frame = video[i]\n",
    "\n",
    "    # Run detection on a single frame using detect\n",
    "    detections = detector.detect(frame[None, ...])[0]\n",
    "    mask = (detections.segmentation.numpy() != 0).astype(np.uint8) * 255\n",
    "\n",
    "    image = np.concatenate((frame, np.zeros_like(frame), mask[..., None]), axis=-1)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Frame', image)\n",
    "    cv2.setWindowTitle('Frame', f'Frame {i} / {len(video)} - prob={detector.prob_threshold}, nms={detector.nms_threshold} - Num detections: {detections.length}')\n",
    "\n",
    "    # Press Q on keyboard to  exit\n",
    "    key = cv2.waitKey() & 0xFF\n",
    "\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "    if cv2.getWindowProperty(\"Frame\", cv2.WND_PROP_VISIBLE) <1:\n",
    "        break\n",
    "        \n",
    "    if key == ord(\"w\"):\n",
    "        i = (i - 1) % len(video)\n",
    "\n",
    "    if key == ord(\"x\"):\n",
    "        i = (i + 1) % len(video)\n",
    "        \n",
    "    if key == ord(\"c\"):\n",
    "        detector.prob_threshold = detector.prob_threshold * (1 - prob_speed)\n",
    "\n",
    "    if key == ord(\"v\"):\n",
    "        detector.prob_threshold = detector.prob_threshold * (1 + prob_speed)\n",
    "\n",
    "    if key == ord(\"b\"):\n",
    "        detector.nms_threshold = detector.nms_threshold * (1 - nms_speed)\n",
    "\n",
    "    if key == ord(\"n\"):\n",
    "        detector.nms_threshold = detector.nms_threshold * (1 + nms_speed)\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0593b3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the detection process on the current video\n",
    "\n",
    "detections_sequence = detector.run(video)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1770513",
   "metadata": {},
   "source": [
    "## Visualize the detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de0d60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first detections\n",
    "\n",
    "segmentation = detections_sequence[0].segmentation.clone()\n",
    "segmentation[segmentation!=0] += 50  # Improve visibility of firsts labels\n",
    "\n",
    "plt.figure(figsize=(24, 16), dpi=100)\n",
    "plt.imshow(segmentation)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da74f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the detections with opencv\n",
    "# Use w/x to move forward in time (or space to run/pause the video)\n",
    "# Use v to switch on/off the display of the video\n",
    "# Use d to switch detection display mode (None, mask, segmentation)\n",
    "\n",
    "byotrack.visualize.InteractiveVisualizer(video, detections_sequence).run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
